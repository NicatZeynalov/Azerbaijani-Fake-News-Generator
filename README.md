# Azerbaijani Fake News Generator
A language model can predict the probability of the next word in the sequence, based on the words already observed in the sequence. Neural network models are a preferred method for developing statistical language models because they can use a distributed representation where
different words with similar meanings have similar representation and because they can use a large context of recently observed words when making predictions. The aim of this project is to generate fake news in the Azerbaijani language using LSTM Recurrent Neural Networks. LSTM Recurrent Neural Networks are powerful Deep Learning models which are used for learning sequenced data. 


In this project a LSTM model is used and trained on 100 thousand samples, and it should be able to generate text. Data for the training has been scraped from the most popular news website of Azerbaijan. 

Model accuracy is about 70% over the 50 epochs. I have used all possible methods to avoid overfitting.

NB! I have shared only a small piece of sample data.

